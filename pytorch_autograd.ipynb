{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+6t9/kUnlbTdGHoacnovX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQBquDMqBum5","executionInfo":{"status":"ok","timestamp":1745233607728,"user_tz":-330,"elapsed":6072,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"2b4fbcff-8795-4484-a6c2-9a14115dae59"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0+cu124\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","source":["#when we write requires_grad= True, it creates computation graph. can write the argument only with floating numbers\n","x = torch.tensor(3.0,requires_grad=True)\n","\n","print(x)\n","\n","\n","y = x ** 2\n","\n","print(y)\n","\n","#It calculate derivative (dy/dx)\n","y.backward()\n","\n","print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0tUsfpOB1MH","executionInfo":{"status":"ok","timestamp":1745233930486,"user_tz":-330,"elapsed":63,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"523f66d0-5ecb-45ae-cc05-8c03b2c47164"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(3., requires_grad=True)\n","tensor(9., grad_fn=<PowBackward0>)\n","tensor(6.)\n"]}]},{"cell_type":"code","source":["x = torch.tensor(2.0,requires_grad=True)\n","print(x)\n","\n","y = x ** 3\n","print(y)\n","\n","z = torch.sin(y)\n","print(z)\n","\n","#It calculate derivative (dz/dx)\n","z.backward()\n","\n","print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omxApDHADt4R","executionInfo":{"status":"ok","timestamp":1745234226430,"user_tz":-330,"elapsed":7,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"100370b7-34f5-4460-86d8-eed741c56a5d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2., requires_grad=True)\n","tensor(8., grad_fn=<PowBackward0>)\n","tensor(0.9894, grad_fn=<SinBackward0>)\n","tensor(-1.7460)\n"]}]},{"cell_type":"markdown","source":["**Autograd in Neural Network**"],"metadata":{"id":"XrsL4cMNFPxQ"}},{"cell_type":"code","source":["x = torch.tensor(6.7) #Input feature\n","y = torch.tensor(0.0) #True label(binary)\n","\n","w = torch.tensor(1.0) #Weight\n","b = torch.tensor(0.0) #Bias\n","\n","\n","#Binary cross entropy loss\n","def binary_cross_entropy_loss(prediction,target):\n","  epsilon = 1e-8\n","  prediction = torch.clamp(prediction,epsilon,1-epsilon)\n","  loss = -(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))\n","  return loss\n","\n","\n","#Forward pass\n","z = w * x + b #weighted sum\n","y_pred = torch.sigmoid(z)\n","\n","#Compute binary cross entropy loss\n","loss = binary_cross_entropy_loss(y_pred,y)\n","\n","print(loss)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtkUYu4_FNub","executionInfo":{"status":"ok","timestamp":1745235325889,"user_tz":-330,"elapsed":33,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"9443dde6-9d56-4105-8f4f-675184eb8d2e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6.7012)\n"]}]},{"cell_type":"code","source":["#Derivatives:\n","\n","#1. dL/d(y_pred): Loss wrt prediction(y_pred)\n","dloss_dy_pred = (y_pred - y)/(y_pred * (1-y_pred))\n","\n","#2.dy_pred/dz = Prediction(y_pred) wrt to z(sigmoid derivative)\n","dy_pred_dz = y_pred * (1-y_pred)\n","\n","#3.dz/dw  and dz/db: z wrt to w and b\n","dz_dw = x\n","dz_db = 1\n","\n","dL_dw = dloss_dy_pred * dy_pred_dz * dz_dw\n","dL_db = dloss_dy_pred * dy_pred_dz * dz_db\n","\n","print(f\"Manual gradient of loss wrt to weight is {dL_dw}\")\n","print(f\"Manual gradient of loss wrt to bias is {dL_db}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkfmVpzQIkj9","executionInfo":{"status":"ok","timestamp":1745235888786,"user_tz":-330,"elapsed":5,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"5cc28edd-e3f4-42df-e596-bbc09f8709bb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Manual gradient of loss wrt to weight is 6.691762447357178\n","Manual gradient of loss wrt to bias is 0.998770534992218\n"]}]},{"cell_type":"markdown","source":["**Implementing with Autograd**"],"metadata":{"id":"TYxITvAjK1bc"}},{"cell_type":"code","source":["x = torch.tensor(6.7)\n","y = torch.tensor(0.0)\n","print(x)\n","print(y)\n","\n","w = torch.tensor(1.0,requires_grad=True)\n","b = torch.tensor(0.0,requires_grad=True)\n","print(w)\n","print(b)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7GSmM2sK8nO","executionInfo":{"status":"ok","timestamp":1745236234491,"user_tz":-330,"elapsed":7,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"5485e641-d04c-4596-f148-98114b11dc4f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6.7000)\n","tensor(0.)\n","tensor(1., requires_grad=True)\n","tensor(0., requires_grad=True)\n"]}]},{"cell_type":"code","source":["z = w * x + b\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHH0DqMDL6Wc","executionInfo":{"status":"ok","timestamp":1745236265523,"user_tz":-330,"elapsed":73,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"0f2a18f6-4aa0-48f1-8f5f-e25944e45008"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6.7000, grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","source":["y_pred = torch.sigmoid(z)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVVGDsETMCyM","executionInfo":{"status":"ok","timestamp":1745236296134,"user_tz":-330,"elapsed":5,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"6c24a4e0-c9d5-42b6-89fd-cbe2f5e5014c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.9988, grad_fn=<SigmoidBackward0>)\n"]}]},{"cell_type":"code","source":["loss = binary_cross_entropy_loss(y_pred,y)\n","print(loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_kH9PlzMIrA","executionInfo":{"status":"ok","timestamp":1745236311597,"user_tz":-330,"elapsed":5,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"b929d42e-9f31-43ad-e250-51dca8556f41"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6.7012, grad_fn=<NegBackward0>)\n"]}]},{"cell_type":"code","source":["loss.backward()"],"metadata":{"id":"9W7QiMy5MYMj","executionInfo":{"status":"ok","timestamp":1745236389064,"user_tz":-330,"elapsed":14,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["w_grad = w.grad\n","b_grad = b.grad\n","\n","print(f\"Auto grad Gradient of loss wrt to weight is {w_grad}\")\n","print(f\"Auto grad Gradient of loss wrt to bias is {b_grad}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRpxZEjSMfiX","executionInfo":{"status":"ok","timestamp":1745236496263,"user_tz":-330,"elapsed":65,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"505bcaa3-7ffc-4b90-889e-c2438bbeb297"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Auto grad Gradient of loss wrt to weight is 6.6917619705200195\n","Auto grad Gradient of loss wrt to bias is 0.9987704753875732\n"]}]},{"cell_type":"markdown","source":["**Implementing Autograd for multidimensional input**"],"metadata":{"id":"P2SfWFOcNshb"}},{"cell_type":"code","source":["x = torch.tensor([1.0,2.0,3.0],requires_grad=True)\n","print(x)\n","\n","y = (x ** 2).mean()\n","print(y)\n","\n","y.backward()\n","print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hh6UbYZXNx0o","executionInfo":{"status":"ok","timestamp":1745236827544,"user_tz":-330,"elapsed":7,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"dff35057-d583-4507-b7d4-e0ad27a36bd7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3.], requires_grad=True)\n","tensor(4.6667, grad_fn=<MeanBackward0>)\n","tensor([0.6667, 1.3333, 2.0000])\n"]}]},{"cell_type":"markdown","source":["**Clearing gradient(necessary for multi forward and backward pass)**"],"metadata":{"id":"G6MbFBInOu98"}},{"cell_type":"code","source":["x = torch.tensor(2.0,requires_grad=True)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E94v_MtuQJRQ","executionInfo":{"status":"ok","timestamp":1745237352622,"user_tz":-330,"elapsed":34,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"a1d53bb8-8f3e-437c-8e54-79455b3d962b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2., requires_grad=True)\n"]}]},{"cell_type":"code","source":["y = (x ** 2)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzpFkqyqPz-r","executionInfo":{"status":"ok","timestamp":1745237474778,"user_tz":-330,"elapsed":4,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"3deb2f3d-c72c-450f-8ca3-c78b791fbbe7"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4., grad_fn=<PowBackward0>)\n"]}]},{"cell_type":"code","source":["y.backward()"],"metadata":{"id":"YCK7WIXNP7rK","executionInfo":{"status":"ok","timestamp":1745237475925,"user_tz":-330,"elapsed":4,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JazcxLVMQAJ9","executionInfo":{"status":"ok","timestamp":1745237478159,"user_tz":-330,"elapsed":4,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"f794d8f4-b197-447e-eec7-b7d4d001500a"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(8.)\n"]}]},{"cell_type":"code","source":["#Try running above code cell starting from y and run without running this cell multiple times to observe the difference in x.grad value\n","x.grad.zero_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VOjT1hvQRhu","executionInfo":{"status":"ok","timestamp":1745237479318,"user_tz":-330,"elapsed":11,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"3f4212c0-00ec-4662-a7b1-67a1b24e8d1d"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["#Disable gradient tracking(useful for forward pass only[inference time])\n","\n","#Option 1: requires_grad_(False)\n","#Option 2: detach()\n","#Option 3: torch.no_grad()\n","\n","x.requires_grad_(False)\n","print(x)\n","\n","y = x ** 2\n","print(y)\n","\n","#y.backward() - will throw error\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hou0qLIsRf45","executionInfo":{"status":"ok","timestamp":1745237921144,"user_tz":-330,"elapsed":52,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"f0cac41b-96e7-41c8-83ea-c3b6e0e7f8bf"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.)\n","tensor(4.)\n"]}]},{"cell_type":"code","source":["#Option 2\n","\n","x = torch.tensor(2.0,requires_grad=True)\n","print(x)\n","\n","z = x.detach()\n","print(z)\n","\n","y = x ** 2\n","print(y)\n","\n","y1 = z ** 2\n","print(y1)\n","\n","y.backward()\n","\n","y1.backward() #It will throw error since gradient is disabled"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMIXQaRAStBO","executionInfo":{"status":"ok","timestamp":1745238214735,"user_tz":-330,"elapsed":26,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"9ecb1cbb-3f58-481a-c514-315c7865ba04"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2., requires_grad=True)\n","tensor(2.)\n","tensor(4., grad_fn=<PowBackward0>)\n","tensor(4.)\n"]}]},{"cell_type":"code","source":["#Option 3\n","\n","x = torch.tensor(2.0,requires_grad=True)\n","print(x)\n","\n","with torch.no_grad():\n","  y = x ** 2\n","  print(y)\n","\n","#y.backward() will throw error\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJfVLJDLTnln","executionInfo":{"status":"ok","timestamp":1745238326145,"user_tz":-330,"elapsed":5,"user":{"displayName":"kiran punjabi","userId":"07898034048161248484"}},"outputId":"3cbe4454-95fa-4a10-9a93-a453d3267d27"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2., requires_grad=True)\n","tensor(4.)\n"]}]}]}